{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease\n",
    "\n",
    "Recently, machine learning is being used to diagnose diseases at the earliest stage. This also helps the doctors to reduce the cost of health care. For this purpose, some data has been collected at [UCI machine learning data set](http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data) .\n",
    "\n",
    "The features or attributes are\n",
    "\n",
    "- age - age in years      \n",
    "- sex - sex (1 = male; 0 = female)       \n",
    "- cp: chest pain type\n",
    "- trestbpss: resting blood pressure (in mm Hg on admission to the hospital)  \n",
    "- chol: serum cholestoral in mg/dl      \n",
    "- fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)       \n",
    "- restecg: resting electrocardiographic results\n",
    "- thalach : maximum heart rate achieved\n",
    "- exang : exercise induced angina (1 = yes; 0 = no)\n",
    "- oldpeak : ST depression induced by exercise relative to rest\n",
    "- slope : the slope of the peak exercise ST segment\n",
    "- ca : number of major vessels (0-3) colored by flourosopy\n",
    "- thal : 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "\n",
    "The target is \n",
    "- num : diagnosis of heart disease (angiographic disease status) - values range from 0 - 4\n",
    "\n",
    "All the above 13 attributes are used to predict the target. \n",
    "\n",
   
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive, Bayes, KNN, Decision Tree, Random Forest\n",
    "#Hyperparameter tuning\n",
    "#Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbpss</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbpss   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0      145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0      160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0      120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0      130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0      130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca thal  num  \n",
       "0    3.0  0.0  6.0    0  \n",
       "1    2.0  3.0  3.0    2  \n",
       "2    2.0  2.0  7.0    1  \n",
       "3    3.0  0.0  3.0    0  \n",
       "4    1.0  0.0  3.0    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "colnames = ['age','sex','cp','trestbpss','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num']\n",
    "data = pd.read_csv(\"processed.cleveland.data\", names = colnames)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace Labels to Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.num = data.num.replace({2: 1, 3:1, 4:1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Object to Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          float64\n",
       "sex          float64\n",
       "cp           float64\n",
       "trestbpss    float64\n",
       "chol         float64\n",
       "fbs          float64\n",
       "restecg      float64\n",
       "thalach      float64\n",
       "exang        float64\n",
       "oldpeak      float64\n",
       "slope        float64\n",
       "ca            object\n",
       "thal          object\n",
       "num            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    176\n",
       "1.0     65\n",
       "2.0     38\n",
       "3.0     20\n",
       "?        4\n",
       "Name: ca, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ca.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Nans with the Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.thal = data.thal.replace({'?': 3.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ca = data.ca.replace({'?': 0.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[data.thal != -1]\n",
    "# data = data[data.ca != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          float64\n",
       "sex          float64\n",
       "cp           float64\n",
       "trestbpss    float64\n",
       "chol         float64\n",
       "fbs          float64\n",
       "restecg      float64\n",
       "thalach      float64\n",
       "exang        float64\n",
       "oldpeak      float64\n",
       "slope        float64\n",
       "ca           float64\n",
       "thal         float64\n",
       "num            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"ca\"] = pd.to_numeric(data[\"ca\"])\n",
    "data[\"thal\"] = pd.to_numeric(data[\"thal\"])\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    168\n",
       "7.0    117\n",
       "6.0     18\n",
       "Name: thal, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.thal.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    164\n",
       "1    139\n",
       "Name: num, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Feature Selection, Checking Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbpss</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.097542</td>\n",
       "      <td>0.104139</td>\n",
       "      <td>0.284946</td>\n",
       "      <td>0.208950</td>\n",
       "      <td>0.118530</td>\n",
       "      <td>0.148868</td>\n",
       "      <td>-0.393806</td>\n",
       "      <td>0.091661</td>\n",
       "      <td>0.203805</td>\n",
       "      <td>0.161770</td>\n",
       "      <td>0.365323</td>\n",
       "      <td>0.128303</td>\n",
       "      <td>0.223120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-0.097542</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>-0.064456</td>\n",
       "      <td>-0.199915</td>\n",
       "      <td>0.047862</td>\n",
       "      <td>0.021647</td>\n",
       "      <td>-0.048663</td>\n",
       "      <td>0.146201</td>\n",
       "      <td>0.102173</td>\n",
       "      <td>0.037533</td>\n",
       "      <td>0.086048</td>\n",
       "      <td>0.380581</td>\n",
       "      <td>0.276816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp</th>\n",
       "      <td>0.104139</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.036077</td>\n",
       "      <td>0.072319</td>\n",
       "      <td>-0.039975</td>\n",
       "      <td>0.067505</td>\n",
       "      <td>-0.334422</td>\n",
       "      <td>0.384060</td>\n",
       "      <td>0.202277</td>\n",
       "      <td>0.152050</td>\n",
       "      <td>0.233117</td>\n",
       "      <td>0.262089</td>\n",
       "      <td>0.414446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trestbpss</th>\n",
       "      <td>0.284946</td>\n",
       "      <td>-0.064456</td>\n",
       "      <td>-0.036077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.130120</td>\n",
       "      <td>0.175340</td>\n",
       "      <td>0.146560</td>\n",
       "      <td>-0.045351</td>\n",
       "      <td>0.064762</td>\n",
       "      <td>0.189171</td>\n",
       "      <td>0.117382</td>\n",
       "      <td>0.097528</td>\n",
       "      <td>0.134424</td>\n",
       "      <td>0.150825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chol</th>\n",
       "      <td>0.208950</td>\n",
       "      <td>-0.199915</td>\n",
       "      <td>0.072319</td>\n",
       "      <td>0.130120</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>0.171043</td>\n",
       "      <td>-0.003432</td>\n",
       "      <td>0.061310</td>\n",
       "      <td>0.046564</td>\n",
       "      <td>-0.004062</td>\n",
       "      <td>0.123726</td>\n",
       "      <td>0.018351</td>\n",
       "      <td>0.085164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbs</th>\n",
       "      <td>0.118530</td>\n",
       "      <td>0.047862</td>\n",
       "      <td>-0.039975</td>\n",
       "      <td>0.175340</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069564</td>\n",
       "      <td>-0.007854</td>\n",
       "      <td>0.025665</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.059894</td>\n",
       "      <td>0.140764</td>\n",
       "      <td>0.064625</td>\n",
       "      <td>0.025264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restecg</th>\n",
       "      <td>0.148868</td>\n",
       "      <td>0.021647</td>\n",
       "      <td>0.067505</td>\n",
       "      <td>0.146560</td>\n",
       "      <td>0.171043</td>\n",
       "      <td>0.069564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.083389</td>\n",
       "      <td>0.084867</td>\n",
       "      <td>0.114133</td>\n",
       "      <td>0.133946</td>\n",
       "      <td>0.131749</td>\n",
       "      <td>0.024325</td>\n",
       "      <td>0.169202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thalach</th>\n",
       "      <td>-0.393806</td>\n",
       "      <td>-0.048663</td>\n",
       "      <td>-0.334422</td>\n",
       "      <td>-0.045351</td>\n",
       "      <td>-0.003432</td>\n",
       "      <td>-0.007854</td>\n",
       "      <td>-0.083389</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.378103</td>\n",
       "      <td>-0.343085</td>\n",
       "      <td>-0.385601</td>\n",
       "      <td>-0.265699</td>\n",
       "      <td>-0.274142</td>\n",
       "      <td>-0.417167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exang</th>\n",
       "      <td>0.091661</td>\n",
       "      <td>0.146201</td>\n",
       "      <td>0.384060</td>\n",
       "      <td>0.064762</td>\n",
       "      <td>0.061310</td>\n",
       "      <td>0.025665</td>\n",
       "      <td>0.084867</td>\n",
       "      <td>-0.378103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.288223</td>\n",
       "      <td>0.257748</td>\n",
       "      <td>0.145788</td>\n",
       "      <td>0.325240</td>\n",
       "      <td>0.431894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldpeak</th>\n",
       "      <td>0.203805</td>\n",
       "      <td>0.102173</td>\n",
       "      <td>0.202277</td>\n",
       "      <td>0.189171</td>\n",
       "      <td>0.046564</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.114133</td>\n",
       "      <td>-0.343085</td>\n",
       "      <td>0.288223</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577537</td>\n",
       "      <td>0.301067</td>\n",
       "      <td>0.342405</td>\n",
       "      <td>0.424510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slope</th>\n",
       "      <td>0.161770</td>\n",
       "      <td>0.037533</td>\n",
       "      <td>0.152050</td>\n",
       "      <td>0.117382</td>\n",
       "      <td>-0.004062</td>\n",
       "      <td>0.059894</td>\n",
       "      <td>0.133946</td>\n",
       "      <td>-0.385601</td>\n",
       "      <td>0.257748</td>\n",
       "      <td>0.577537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.110803</td>\n",
       "      <td>0.286792</td>\n",
       "      <td>0.339213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>0.365323</td>\n",
       "      <td>0.086048</td>\n",
       "      <td>0.233117</td>\n",
       "      <td>0.097528</td>\n",
       "      <td>0.123726</td>\n",
       "      <td>0.140764</td>\n",
       "      <td>0.131749</td>\n",
       "      <td>-0.265699</td>\n",
       "      <td>0.145788</td>\n",
       "      <td>0.301067</td>\n",
       "      <td>0.110803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.255446</td>\n",
       "      <td>0.460033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thal</th>\n",
       "      <td>0.128303</td>\n",
       "      <td>0.380581</td>\n",
       "      <td>0.262089</td>\n",
       "      <td>0.134424</td>\n",
       "      <td>0.018351</td>\n",
       "      <td>0.064625</td>\n",
       "      <td>0.024325</td>\n",
       "      <td>-0.274142</td>\n",
       "      <td>0.325240</td>\n",
       "      <td>0.342405</td>\n",
       "      <td>0.286792</td>\n",
       "      <td>0.255446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.522057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num</th>\n",
       "      <td>0.223120</td>\n",
       "      <td>0.276816</td>\n",
       "      <td>0.414446</td>\n",
       "      <td>0.150825</td>\n",
       "      <td>0.085164</td>\n",
       "      <td>0.025264</td>\n",
       "      <td>0.169202</td>\n",
       "      <td>-0.417167</td>\n",
       "      <td>0.431894</td>\n",
       "      <td>0.424510</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>0.460033</td>\n",
       "      <td>0.522057</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age       sex        cp  trestbpss      chol       fbs  \\\n",
       "age        1.000000 -0.097542  0.104139   0.284946  0.208950  0.118530   \n",
       "sex       -0.097542  1.000000  0.010084  -0.064456 -0.199915  0.047862   \n",
       "cp         0.104139  0.010084  1.000000  -0.036077  0.072319 -0.039975   \n",
       "trestbpss  0.284946 -0.064456 -0.036077   1.000000  0.130120  0.175340   \n",
       "chol       0.208950 -0.199915  0.072319   0.130120  1.000000  0.009841   \n",
       "fbs        0.118530  0.047862 -0.039975   0.175340  0.009841  1.000000   \n",
       "restecg    0.148868  0.021647  0.067505   0.146560  0.171043  0.069564   \n",
       "thalach   -0.393806 -0.048663 -0.334422  -0.045351 -0.003432 -0.007854   \n",
       "exang      0.091661  0.146201  0.384060   0.064762  0.061310  0.025665   \n",
       "oldpeak    0.203805  0.102173  0.202277   0.189171  0.046564  0.005747   \n",
       "slope      0.161770  0.037533  0.152050   0.117382 -0.004062  0.059894   \n",
       "ca         0.365323  0.086048  0.233117   0.097528  0.123726  0.140764   \n",
       "thal       0.128303  0.380581  0.262089   0.134424  0.018351  0.064625   \n",
       "num        0.223120  0.276816  0.414446   0.150825  0.085164  0.025264   \n",
       "\n",
       "            restecg   thalach     exang   oldpeak     slope        ca  \\\n",
       "age        0.148868 -0.393806  0.091661  0.203805  0.161770  0.365323   \n",
       "sex        0.021647 -0.048663  0.146201  0.102173  0.037533  0.086048   \n",
       "cp         0.067505 -0.334422  0.384060  0.202277  0.152050  0.233117   \n",
       "trestbpss  0.146560 -0.045351  0.064762  0.189171  0.117382  0.097528   \n",
       "chol       0.171043 -0.003432  0.061310  0.046564 -0.004062  0.123726   \n",
       "fbs        0.069564 -0.007854  0.025665  0.005747  0.059894  0.140764   \n",
       "restecg    1.000000 -0.083389  0.084867  0.114133  0.133946  0.131749   \n",
       "thalach   -0.083389  1.000000 -0.378103 -0.343085 -0.385601 -0.265699   \n",
       "exang      0.084867 -0.378103  1.000000  0.288223  0.257748  0.145788   \n",
       "oldpeak    0.114133 -0.343085  0.288223  1.000000  0.577537  0.301067   \n",
       "slope      0.133946 -0.385601  0.257748  0.577537  1.000000  0.110803   \n",
       "ca         0.131749 -0.265699  0.145788  0.301067  0.110803  1.000000   \n",
       "thal       0.024325 -0.274142  0.325240  0.342405  0.286792  0.255446   \n",
       "num        0.169202 -0.417167  0.431894  0.424510  0.339213  0.460033   \n",
       "\n",
       "               thal       num  \n",
       "age        0.128303  0.223120  \n",
       "sex        0.380581  0.276816  \n",
       "cp         0.262089  0.414446  \n",
       "trestbpss  0.134424  0.150825  \n",
       "chol       0.018351  0.085164  \n",
       "fbs        0.064625  0.025264  \n",
       "restecg    0.024325  0.169202  \n",
       "thalach   -0.274142 -0.417167  \n",
       "exang      0.325240  0.431894  \n",
       "oldpeak    0.342405  0.424510  \n",
       "slope      0.286792  0.339213  \n",
       "ca         0.255446  0.460033  \n",
       "thal       1.000000  0.522057  \n",
       "num        0.522057  1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbpss</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.438944</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>3.158416</td>\n",
       "      <td>131.689769</td>\n",
       "      <td>246.693069</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>149.607261</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.600660</td>\n",
       "      <td>0.663366</td>\n",
       "      <td>4.722772</td>\n",
       "      <td>0.458746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.038662</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>0.960126</td>\n",
       "      <td>17.599748</td>\n",
       "      <td>51.776918</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>22.875003</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>1.938383</td>\n",
       "      <td>0.499120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp   trestbpss        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.438944    0.679868    3.158416  131.689769  246.693069    0.148515   \n",
       "std      9.038662    0.467299    0.960126   17.599748   51.776918    0.356198   \n",
       "min     29.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.000000    0.000000    3.000000  120.000000  211.000000    0.000000   \n",
       "50%     56.000000    1.000000    3.000000  130.000000  241.000000    0.000000   \n",
       "75%     61.000000    1.000000    4.000000  140.000000  275.000000    0.000000   \n",
       "max     77.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.990099  149.607261    0.326733    1.039604    1.600660    0.663366   \n",
       "std      0.994971   22.875003    0.469794    1.161075    0.616226    0.934375   \n",
       "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    2.000000    0.000000   \n",
       "75%      2.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    3.000000    3.000000   \n",
       "\n",
       "             thal         num  \n",
       "count  303.000000  303.000000  \n",
       "mean     4.722772    0.458746  \n",
       "std      1.938383    0.499120  \n",
       "min      3.000000    0.000000  \n",
       "25%      3.000000    0.000000  \n",
       "50%      3.000000    0.000000  \n",
       "75%      7.000000    1.000000  \n",
       "max      7.000000    1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['num']\n",
    "X = data.drop('num', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "sc = StandardScaler()\n",
    "X[['age','sex','cp','trestbpss','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']] = sc.fit_transform(X[['age','sex','cp','trestbpss','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TrainTest Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM 87%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][[29  4]\n",
      " [ 4 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88        33\n",
      "           1       0.86      0.86      0.86        28\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        61\n",
      "   macro avg       0.87      0.87      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n",
      "Accuracy score:  86.88524590163934 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='rbf', verbose = True)\n",
    "svclassifier.fit(X_train, y_train)\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accuracy score: \", 100*accuracy_score(y_test, y_pred), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29  4]\n",
      " [ 4 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88        33\n",
      "           1       0.86      0.86      0.86        28\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        61\n",
      "   macro avg       0.87      0.87      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n",
      "Accuracy score:  86.88524590163934 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accuracy score: \", 100*accuracy_score(y_test, y_pred), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22 11]\n",
      " [ 7 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71        33\n",
      "           1       0.66      0.75      0.70        28\n",
      "\n",
      "   micro avg       0.70      0.70      0.70        61\n",
      "   macro avg       0.71      0.71      0.70        61\n",
      "weighted avg       0.71      0.70      0.71        61\n",
      "\n",
      "Accuracy score:  70.49180327868852 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accuracy score: \", 100*accuracy_score(y_test, y_pred), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN 89% on neighbors = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[24  9]\n",
      " [ 3 25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.73      0.80        33\n",
      "           1       0.74      0.89      0.81        28\n",
      "\n",
      "   micro avg       0.80      0.80      0.80        61\n",
      "   macro avg       0.81      0.81      0.80        61\n",
      "weighted avg       0.82      0.80      0.80        61\n",
      "\n",
      "Test Accuracy score:  80.32786885245902 %\n",
      "Train Accuracy score:  100.0 %\n",
      "2\n",
      "[[29  4]\n",
      " [ 7 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84        33\n",
      "           1       0.84      0.75      0.79        28\n",
      "\n",
      "   micro avg       0.82      0.82      0.82        61\n",
      "   macro avg       0.82      0.81      0.82        61\n",
      "weighted avg       0.82      0.82      0.82        61\n",
      "\n",
      "Test Accuracy score:  81.9672131147541 %\n",
      "Train Accuracy score:  88.84297520661157 %\n",
      "3\n",
      "[[27  6]\n",
      " [ 5 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83        33\n",
      "           1       0.79      0.82      0.81        28\n",
      "\n",
      "   micro avg       0.82      0.82      0.82        61\n",
      "   macro avg       0.82      0.82      0.82        61\n",
      "weighted avg       0.82      0.82      0.82        61\n",
      "\n",
      "Test Accuracy score:  81.9672131147541 %\n",
      "Train Accuracy score:  91.32231404958677 %\n",
      "4\n",
      "[[29  4]\n",
      " [ 8 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83        33\n",
      "           1       0.83      0.71      0.77        28\n",
      "\n",
      "   micro avg       0.80      0.80      0.80        61\n",
      "   macro avg       0.81      0.80      0.80        61\n",
      "weighted avg       0.81      0.80      0.80        61\n",
      "\n",
      "Test Accuracy score:  80.32786885245902 %\n",
      "Train Accuracy score:  88.01652892561982 %\n",
      "5\n",
      "[[28  5]\n",
      " [ 4 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86        33\n",
      "           1       0.83      0.86      0.84        28\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        61\n",
      "   macro avg       0.85      0.85      0.85        61\n",
      "weighted avg       0.85      0.85      0.85        61\n",
      "\n",
      "Test Accuracy score:  85.24590163934425 %\n",
      "Train Accuracy score:  86.36363636363636 %\n",
      "6\n",
      "[[32  1]\n",
      " [ 7 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89        33\n",
      "           1       0.95      0.75      0.84        28\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        61\n",
      "   macro avg       0.89      0.86      0.86        61\n",
      "weighted avg       0.88      0.87      0.87        61\n",
      "\n",
      "Test Accuracy score:  86.88524590163934 %\n",
      "Train Accuracy score:  85.9504132231405 %\n",
      "7\n",
      "[[31  2]\n",
      " [ 5 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90        33\n",
      "           1       0.92      0.82      0.87        28\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        61\n",
      "   macro avg       0.89      0.88      0.88        61\n",
      "weighted avg       0.89      0.89      0.88        61\n",
      "\n",
      "Test Accuracy score:  88.52459016393442 %\n",
      "Train Accuracy score:  86.36363636363636 %\n",
      "8\n",
      "[[31  2]\n",
      " [ 8 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86        33\n",
      "           1       0.91      0.71      0.80        28\n",
      "\n",
      "   micro avg       0.84      0.84      0.84        61\n",
      "   macro avg       0.85      0.83      0.83        61\n",
      "weighted avg       0.85      0.84      0.83        61\n",
      "\n",
      "Test Accuracy score:  83.60655737704919 %\n",
      "Train Accuracy score:  83.88429752066115 %\n",
      "9\n",
      "[[29  4]\n",
      " [ 6 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85        33\n",
      "           1       0.85      0.79      0.81        28\n",
      "\n",
      "   micro avg       0.84      0.84      0.84        61\n",
      "   macro avg       0.84      0.83      0.83        61\n",
      "weighted avg       0.84      0.84      0.84        61\n",
      "\n",
      "Test Accuracy score:  83.60655737704919 %\n",
      "Train Accuracy score:  83.47107438016529 %\n",
      "10\n",
      "[[31  2]\n",
      " [ 7 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87        33\n",
      "           1       0.91      0.75      0.82        28\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        61\n",
      "   macro avg       0.86      0.84      0.85        61\n",
      "weighted avg       0.86      0.85      0.85        61\n",
      "\n",
      "Test Accuracy score:  85.24590163934425 %\n",
      "Train Accuracy score:  83.47107438016529 %\n",
      "11\n",
      "[[29  4]\n",
      " [ 6 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85        33\n",
      "           1       0.85      0.79      0.81        28\n",
      "\n",
      "   micro avg       0.84      0.84      0.84        61\n",
      "   macro avg       0.84      0.83      0.83        61\n",
      "weighted avg       0.84      0.84      0.84        61\n",
      "\n",
      "Test Accuracy score:  83.60655737704919 %\n",
      "Train Accuracy score:  84.29752066115702 %\n",
      "12\n",
      "[[31  2]\n",
      " [ 8 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86        33\n",
      "           1       0.91      0.71      0.80        28\n",
      "\n",
      "   micro avg       0.84      0.84      0.84        61\n",
      "   macro avg       0.85      0.83      0.83        61\n",
      "weighted avg       0.85      0.84      0.83        61\n",
      "\n",
      "Test Accuracy score:  83.60655737704919 %\n",
      "Train Accuracy score:  84.29752066115702 %\n",
      "13\n",
      "[[30  3]\n",
      " [ 6 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87        33\n",
      "           1       0.88      0.79      0.83        28\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        61\n",
      "   macro avg       0.86      0.85      0.85        61\n",
      "weighted avg       0.85      0.85      0.85        61\n",
      "\n",
      "Test Accuracy score:  85.24590163934425 %\n",
      "Train Accuracy score:  84.29752066115702 %\n",
      "14\n",
      "[[32  1]\n",
      " [ 6 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90        33\n",
      "           1       0.96      0.79      0.86        28\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        61\n",
      "   macro avg       0.90      0.88      0.88        61\n",
      "weighted avg       0.89      0.89      0.88        61\n",
      "\n",
      "Test Accuracy score:  88.52459016393442 %\n",
      "Train Accuracy score:  83.05785123966942 %\n",
      "15\n",
      "[[31  2]\n",
      " [ 6 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89        33\n",
      "           1       0.92      0.79      0.85        28\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        61\n",
      "   macro avg       0.88      0.86      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n",
      "Test Accuracy score:  86.88524590163934 %\n",
      "Train Accuracy score:  83.88429752066115 %\n",
      "16\n",
      "[[32  1]\n",
      " [ 7 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89        33\n",
      "           1       0.95      0.75      0.84        28\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        61\n",
      "   macro avg       0.89      0.86      0.86        61\n",
      "weighted avg       0.88      0.87      0.87        61\n",
      "\n",
      "Test Accuracy score:  86.88524590163934 %\n",
      "Train Accuracy score:  83.47107438016529 %\n",
      "17\n",
      "[[31  2]\n",
      " [ 6 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89        33\n",
      "           1       0.92      0.79      0.85        28\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        61\n",
      "   macro avg       0.88      0.86      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n",
      "Test Accuracy score:  86.88524590163934 %\n",
      "Train Accuracy score:  83.47107438016529 %\n",
      "18\n",
      "[[32  1]\n",
      " [ 6 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90        33\n",
      "           1       0.96      0.79      0.86        28\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        61\n",
      "   macro avg       0.90      0.88      0.88        61\n",
      "weighted avg       0.89      0.89      0.88        61\n",
      "\n",
      "Test Accuracy score:  88.52459016393442 %\n",
      "Train Accuracy score:  83.88429752066115 %\n",
      "19\n",
      "[[30  3]\n",
      " [ 6 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87        33\n",
      "           1       0.88      0.79      0.83        28\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        61\n",
      "   macro avg       0.86      0.85      0.85        61\n",
      "weighted avg       0.85      0.85      0.85        61\n",
      "\n",
      "Test Accuracy score:  85.24590163934425 %\n",
      "Train Accuracy score:  84.29752066115702 %\n",
      "20\n",
      "[[32  1]\n",
      " [ 6 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90        33\n",
      "           1       0.96      0.79      0.86        28\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        61\n",
      "   macro avg       0.90      0.88      0.88        61\n",
      "weighted avg       0.89      0.89      0.88        61\n",
      "\n",
      "Test Accuracy score:  88.52459016393442 %\n",
      "Train Accuracy score:  83.47107438016529 %\n",
      "21\n",
      "[[31  2]\n",
      " [ 6 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89        33\n",
      "           1       0.92      0.79      0.85        28\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        61\n",
      "   macro avg       0.88      0.86      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n",
      "Test Accuracy score:  86.88524590163934 %\n",
      "Train Accuracy score:  84.29752066115702 %\n",
      "22\n",
      "[[32  1]\n",
      " [ 6 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90        33\n",
      "           1       0.96      0.79      0.86        28\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        61\n",
      "   macro avg       0.90      0.88      0.88        61\n",
      "weighted avg       0.89      0.89      0.88        61\n",
      "\n",
      "Test Accuracy score:  88.52459016393442 %\n",
      "Train Accuracy score:  83.88429752066115 %\n",
      "23\n",
      "[[32  1]\n",
      " [ 6 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90        33\n",
      "           1       0.96      0.79      0.86        28\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        61\n",
      "   macro avg       0.90      0.88      0.88        61\n",
      "weighted avg       0.89      0.89      0.88        61\n",
      "\n",
      "Test Accuracy score:  88.52459016393442 %\n",
      "Train Accuracy score:  83.47107438016529 %\n",
      "24\n",
      "[[32  1]\n",
      " [ 6 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90        33\n",
      "           1       0.96      0.79      0.86        28\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        61\n",
      "   macro avg       0.90      0.88      0.88        61\n",
      "weighted avg       0.89      0.89      0.88        61\n",
      "\n",
      "Test Accuracy score:  88.52459016393442 %\n",
      "Train Accuracy score:  83.05785123966942 %\n",
      "25\n",
      "[[31  2]\n",
      " [ 6 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89        33\n",
      "           1       0.92      0.79      0.85        28\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        61\n",
      "   macro avg       0.88      0.86      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n",
      "Test Accuracy score:  86.88524590163934 %\n",
      "Train Accuracy score:  84.29752066115702 %\n",
      "26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31  2]\n",
      " [ 6 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89        33\n",
      "           1       0.92      0.79      0.85        28\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        61\n",
      "   macro avg       0.88      0.86      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n",
      "Test Accuracy score:  86.88524590163934 %\n",
      "Train Accuracy score:  83.47107438016529 %\n",
      "27\n",
      "[[31  2]\n",
      " [ 6 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89        33\n",
      "           1       0.92      0.79      0.85        28\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        61\n",
      "   macro avg       0.88      0.86      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n",
      "Test Accuracy score:  86.88524590163934 %\n",
      "Train Accuracy score:  83.47107438016529 %\n",
      "28\n",
      "[[31  2]\n",
      " [ 6 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89        33\n",
      "           1       0.92      0.79      0.85        28\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        61\n",
      "   macro avg       0.88      0.86      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n",
      "Test Accuracy score:  86.88524590163934 %\n",
      "Train Accuracy score:  83.05785123966942 %\n",
      "29\n",
      "[[30  3]\n",
      " [ 6 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87        33\n",
      "           1       0.88      0.79      0.83        28\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        61\n",
      "   macro avg       0.86      0.85      0.85        61\n",
      "weighted avg       0.85      0.85      0.85        61\n",
      "\n",
      "Test Accuracy score:  85.24590163934425 %\n",
      "Train Accuracy score:  84.29752066115702 %\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,30):\n",
    "    print(i)\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    classifier = KNeighborsClassifier(n_neighbors = i)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(\"Test Accuracy score: \", 100*accuracy_score(y_test, y_pred), \"%\")\n",
    "\n",
    "    y_pred_train = classifier.predict(X_train)\n",
    "    print(\"Train Accuracy score: \", 100*accuracy_score(y_train, y_pred_train), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  6]\n",
      " [ 5 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83        33\n",
      "           1       0.79      0.82      0.81        28\n",
      "\n",
      "   micro avg       0.82      0.82      0.82        61\n",
      "   macro avg       0.82      0.82      0.82        61\n",
      "weighted avg       0.82      0.82      0.82        61\n",
      "\n",
      "Test Accuracy score:  81.9672131147541 %\n",
      "Train Accuracy score:  83.47107438016529 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "k_range = list(range(1, 31))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "knn = KNeighborsClassifier()\n",
    "grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Test Accuracy score: \", 100*accuracy_score(y_test, y_pred), \"%\")\n",
    "\n",
    "y_pred_train = classifier.predict(X_train)\n",
    "print(\"Train Accuracy score: \", 100*accuracy_score(y_train, y_pred_train), \"%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes 89%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31  2]\n",
      " [ 5 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90        33\n",
      "           1       0.92      0.82      0.87        28\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        61\n",
      "   macro avg       0.89      0.88      0.88        61\n",
      "weighted avg       0.89      0.89      0.88        61\n",
      "\n",
      "Test Accuracy score:  88.52459016393442 %\n",
      "Train Accuracy score:  85.12396694214877 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Test Accuracy score: \", 100*accuracy_score(y_test, y_pred), \"%\")\n",
    "\n",
    "y_pred_train = gnb.fit(X_train, y_train).predict(X_train)\n",
    "print(\"Train Accuracy score: \", 100*accuracy_score(y_train, y_pred_train), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  1]\n",
      " [ 5 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91        33\n",
      "           1       0.96      0.82      0.88        28\n",
      "\n",
      "   micro avg       0.90      0.90      0.90        61\n",
      "   macro avg       0.91      0.90      0.90        61\n",
      "weighted avg       0.91      0.90      0.90        61\n",
      "\n",
      "Test Accuracy score:  90.1639344262295 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy score:  83.47107438016529 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "y_pred = lr.fit(X_train, y_train).predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Test Accuracy score: \", 100*accuracy_score(y_test, y_pred), \"%\")\n",
    "\n",
    "y_pred_train = lr.fit(X_train, y_train).predict(X_train)\n",
    "print(\"Train Accuracy score: \", 100*accuracy_score(y_train, y_pred_train), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  3]\n",
      " [ 5 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88        33\n",
      "           1       0.88      0.82      0.85        28\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        61\n",
      "   macro avg       0.87      0.87      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n",
      "Accuracy score:  86.88524590163934 %\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Train Accuracy score:  83.05785123966942 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "log_reg_grid = {\"C\" : np.logspace(-4, 4, 30),\n",
    "                \"solver\" : [\"liblinear\"]}\n",
    "rs_log_reg = RandomizedSearchCV(LogisticRegression(),\n",
    "                               param_distributions=log_reg_grid,\n",
    "                               cv=5,\n",
    "                               n_iter=20,\n",
    "                               verbose=True)\n",
    "\n",
    "y_pred = rs_log_reg.fit(X_train, y_train).predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accuracy score: \", 100*accuracy_score(y_test, y_pred), \"%\")\n",
    "\n",
    "y_pred_train = rs_log_reg.fit(X_train, y_train).predict(X_train)\n",
    "print(\"Train Accuracy score: \", 100*accuracy_score(y_train, y_pred_train), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier with RandomizedSearchCV 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   53.3s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31  2]\n",
      " [ 7 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87        33\n",
      "           1       0.91      0.75      0.82        28\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        61\n",
      "   macro avg       0.86      0.84      0.85        61\n",
      "weighted avg       0.86      0.85      0.85        61\n",
      "\n",
      "Test Accuracy score:  85.24590163934425 %\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_grid = {\"n_estimators\" : np.arange(11,1001,30),\n",
    "           \"max_depth\" : [None, 2, 6, 9],\n",
    "           \"min_samples_split\" : np.arange(3,20,3),\n",
    "           \"min_samples_leaf\" : np.arange(3,20,2)}\n",
    "\n",
    "rs_rf = RandomizedSearchCV(RandomForestClassifier(),\n",
    "                               param_distributions=rf_grid,\n",
    "                               cv=5,\n",
    "                               n_iter=20,\n",
    "                               verbose=True)\n",
    "\n",
    "y_pred = rs_rf.fit(X_train, y_train).predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Test Accuracy score: \", 100*accuracy_score(y_test, y_pred), \"%\")\n",
    "\n",
    "y_pred_train = rs_rf.fit(X_train, y_train).predict(X_train)\n",
    "print(\"Train Accuracy score: \", 100*accuracy_score(y_train, y_pred_train), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 750 out of 750 | elapsed:    6.5s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  3]\n",
      " [ 5 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88        33\n",
      "           1       0.88      0.82      0.85        28\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        61\n",
      "   macro avg       0.87      0.87      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n",
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n",
      "Train Accuracy score:  83.47107438016529 %\n",
      "Test Accuracy score:  86.88524590163934 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 750 out of 750 | elapsed:    6.5s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "log_reg_grid = {\"C\" : np.logspace(-4, 4, 30),\n",
    "                \"solver\" : [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]}\n",
    "grid_log_reg = GridSearchCV(LogisticRegression(),\n",
    "                               param_grid=log_reg_grid,\n",
    "                               cv=5,\n",
    "                               verbose=True)\n",
    "\n",
    "y_pred = grid_log_reg.fit(X_train, y_train).predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "y_pred_train = grid_log_reg.fit(X_train, y_train).predict(X_train)\n",
    "print(\"Train Accuracy score: \", 100*accuracy_score(y_train, y_pred_train), \"%\")\n",
    "print(\"Test Accuracy score: \", 100*accuracy_score(y_test, y_pred), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33  0]\n",
      " [ 8 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        33\n",
      "           1       1.00      0.71      0.83        28\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        61\n",
      "   macro avg       0.90      0.86      0.86        61\n",
      "weighted avg       0.89      0.87      0.87        61\n",
      "\n",
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy score:  83.47107438016529 %\n",
      "Test Accuracy score:  86.88524590163934 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 750 out of 750 | elapsed:    7.3s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "clf = LogisticRegressionCV(cv=5, random_state=0)\n",
    "\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "y_pred_train = grid_log_reg.fit(X_train, y_train).predict(X_train)\n",
    "print(\"Train Accuracy score: \", 100*accuracy_score(y_train, y_pred_train), \"%\")\n",
    "print(\"Test Accuracy score: \", 100*accuracy_score(y_test, y_pred), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best accuracies after rigorous hyperparamter tuning\n",
    "\n",
    "**Logistic Regression: 90%**\n",
    "\n",
    "Naive Bayes: 89%\n",
    "\n",
    "KNN: 89%\n",
    "\n",
    "SVM: 87%\n",
    "\n",
    "Random Forest: 85%\n",
    "\n",
    "Decision Tree: 70%\n",
    "\n",
    "**Hyperparameter techniques Used:**\n",
    "\n",
    "1- GridSearchCV was used to consider all combinations of hyperparameters and get the best accuracy.\n",
    "\n",
    "2- RandomizedSearchCV was the fastest way to find optimal best accuracy by checking optimal combinations of hyperparameters\n",
    "\n",
    "3- Randomly, based on theory and distributions of data, particular hyperparameters were selected. In KNN, for loop was used to find best neighbors. In SVM, gaussian distribution was used. etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
